{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from numpy.linalg import LinAlgError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gen_param_dict(object):\n",
    "    '''\n",
    "    Init function not required. Currently there for debugging.\n",
    "        init: define the class constructor of with no arguments\n",
    "    '''\n",
    "    def __init__(self, verbose=True):\n",
    "        self.verbose = verbose\n",
    "        if self.verbose:\n",
    "            print('-'*25)\n",
    "            print('Call to the class gen_param_dict has started')\n",
    "            print('-'*25)\n",
    "        \n",
    "    def gen_param_ALG(self, inner_iterations=1, min_eta=1e-5, kl_step=0.2, min_step_mult=0.01,\n",
    "                     max_step_mult=10.0, min_mult=0.1, max_mult=5.0, initial_state_var=1e-6, \n",
    "                     init_traj_distr=None, traj_opt=None, max_ent_traj=0.0, dynamics=None, \n",
    "                     cost=None, sample_on_policy=False, fit_dynamics=True):\n",
    "        # Algorithm\n",
    "        ALG = {\n",
    "            # Number of iterations.\n",
    "            'inner_iterations': inner_iterations,  \n",
    "            # Minimum initial lagrange multiplier in DGD for trajectory optimization.\n",
    "            'min_eta': min_eta,        \n",
    "            'kl_step': kl_step,\n",
    "            'min_step_mult': min_step_mult,\n",
    "            'max_step_mult': max_step_mult,\n",
    "            'min_mult': min_mult,\n",
    "            'max_mult': max_mult,\n",
    "            # Trajectory settings.\n",
    "            'initial_state_var': initial_state_var,\n",
    "            # A list of initial LinearGaussianPolicy objects for each condition.\n",
    "            'init_traj_distr': init_traj_distr, \n",
    "            # Trajectory optimization.\n",
    "            'traj_opt': traj_opt,\n",
    "            # Weight of maximum entropy term in trajectory optimization.\n",
    "            'max_ent_traj': max_ent_traj,\n",
    "            # Dynamics hyperaparams.\n",
    "            'dynamics': dynamics,\n",
    "            # Costs.\n",
    "            'cost': cost,  # A list of Cost objects for each condition.\n",
    "            # Whether or not to sample with neural net policy (only for badmm/mdgps).\n",
    "            'sample_on_policy': sample_on_policy,\n",
    "            # Inidicates if the algorithm requires fitting of the dynamics.\n",
    "            'fit_dynamics': fit_dynamics,    \n",
    "        }\n",
    "        return ALG\n",
    "    \n",
    "    def gen_param_ALG_BADMM(self, inner_iterations=4.0, policy_dual_rate=0.1, policy_dual_rate_covar=0.0,\n",
    "                           fixed_lg_step=0.0, lg_step_schedule=10.0, ent_reg_schedule=0.0, init_pol_wt=0.01,\n",
    "                           policy_sample_mode='add', exp_step_increase=2.0, exp_step_decrease=0.5, \n",
    "                            exp_step_upper=0.5, exp_step_lower=1.0): \n",
    "        # Algorithm BADMM\n",
    "        ALG_BADMM = {\n",
    "            'inner_iterations': inner_iterations,\n",
    "            'policy_dual_rate': policy_dual_rate,\n",
    "            'policy_dual_rate_covar': policy_dual_rate_covar,\n",
    "            'fixed_lg_step': fixed_lg_step,\n",
    "            'lg_step_schedule': lg_step_schedule,\n",
    "            'ent_reg_schedule': ent_reg_schedule,\n",
    "            'init_pol_wt': init_pol_wt,\n",
    "            'policy_sample_mode': policy_sample_mode,\n",
    "            'exp_step_increase': exp_step_increase,\n",
    "            'exp_step_decrease': exp_step_decrease,\n",
    "            'exp_step_upper': exp_step_upper,\n",
    "            'exp_step_lower': exp_step_lower,\n",
    "        }\n",
    "        return ALG_BADMM\n",
    "    \n",
    "    def gen_param_TRAJ_OPT_LQR(self, del0=1e-4, eta_error_threshold=1e16, min_eta=1e-8, max_eta=1e16,\n",
    "                              cons_per_step=False, use_prev_distr=False, update_in_bwd_pass=True):\n",
    "        TRAJ_OPT_LQR = {\n",
    "            'del0': del0,\n",
    "            'eta_error_threshold': eta_error_threshold,\n",
    "            'min_eta': min_eta,\n",
    "            'max_eta': max_eta,\n",
    "            # Whether or not to enforce separate KL constraints at each time step.\n",
    "            'cons_per_step': cons_per_step,  \n",
    "            # Whether or not to measure expected KL under the previous traj distr.\n",
    "            'use_prev_distr': use_prev_distr,  \n",
    "            # Whether or not to update the TVLG controller during the bwd pass.\n",
    "            'update_in_bwd_pass': update_in_bwd_pass,  \n",
    "        }\n",
    "        return TRAJ_OPT_LQR\n",
    "    \n",
    "    def gen_param_INIT_LG_LQR(self, init_var=1.0, stiffness=1.0, stiffness_vel=0.5,\n",
    "                             final_weight=1.0):\n",
    "        # Initial Linear Gaussian Trajectory distribution, LQR-based initializer.\n",
    "        INIT_LG_LQR = {\n",
    "            'init_var': init_var,\n",
    "            'stiffness': stiffness,\n",
    "            'stiffness_vel': stiffness_vel,\n",
    "            'final_weight': final_weight,\n",
    "            # Parameters for guessing dynamics\n",
    "            # dU vector of accelerations, default zeros.\n",
    "            'init_acc': [],  \n",
    "            # dU vector of gains, default ones.\n",
    "            'init_gains': [],  \n",
    "        }\n",
    "        return INIT_LG_LQR\n",
    "    \n",
    "    def gen_param_POLICY_PRIOR(self, strength=1e-4):\n",
    "        # PolicyPrior\n",
    "        POLICY_PRIOR = {\n",
    "            'strength': strength,\n",
    "        }\n",
    "        return POLICY_PRIOR\n",
    "    \n",
    "    def gen_param_POLICY_PRIOR_GMM(self, min_samples_per_cluster=20.0, max_clusters=50.0, max_samples=20.0,\n",
    "                                  strength=1.0):\n",
    "        # PolicyPriorGMM\n",
    "        POLICY_PRIOR_GMM = {\n",
    "            'min_samples_per_cluster': min_samples_per_cluster,\n",
    "            'max_clusters': max_clusters,\n",
    "            'max_samples': max_samples,\n",
    "            'strength': strength,\n",
    "        }\n",
    "        return POLICY_PRIOR_GMM\n",
    "    \n",
    "    def gen_param_COST_STATE(self, RAMP_CONSTANT, l1=0.0, l2=1.0, alpha=1e-2, wp_final_multiplier=1.0, \n",
    "                            target_state=None, wp=None):\n",
    "        # CostState\n",
    "        COST_STATE = {\n",
    "            # How target cost ramps over time.\n",
    "            'ramp_option': RAMP_CONSTANT,  \n",
    "            'l1': l1,\n",
    "            'l2': l2,\n",
    "            'alpha': alpha,\n",
    "            # Weight multiplier on final time step.\n",
    "            'wp_final_multiplier': 1.0,  \n",
    "            'data_types': {\n",
    "                'JointAngle': {\n",
    "                    # Target state - must be set.\n",
    "                    'target_state': target_state,  \n",
    "                    # State weights - must be set.\n",
    "                    'wp': wp,  \n",
    "                },\n",
    "            },\n",
    "        }\n",
    "        return COST_STATE\n",
    "    \n",
    "    def gen_param_COST_SUM(self, costs=[], weights=[]):\n",
    "        # CostSum\n",
    "        COST_SUM = {\n",
    "            # A list of hyperparam dictionaries for each cost.\n",
    "            'costs': costs,  \n",
    "            # Weight multipliers for each cost.\n",
    "            'weights': weights,  \n",
    "        }\n",
    "        return COST_SUM\n",
    "    \n",
    "    def gen_param_COST_ACTION(self, wu=np.array([])):\n",
    "        # CostAction\n",
    "        COST_ACTION = {\n",
    "            # Torque penalties, must be 1 x dU numpy array.\n",
    "            'wu': np.array([]),  \n",
    "        }\n",
    "        return COST_ACTION\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required class for different functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class General Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class general_utlis(object):\n",
    "    '''\n",
    "    Init function not required. Currently there for debugging.\n",
    "        init: define the class constructor of with no arguments\n",
    "    '''\n",
    "    def __init__(self, verbose=True):\n",
    "        self.verbose = verbose\n",
    "        if self.verbose:\n",
    "            print('-'*25)\n",
    "            print('Call to the class general_utlis has started')\n",
    "            print('-'*25)\n",
    "    \n",
    "    def check_shape(self, value, expected_shape, name=''):\n",
    "    \"\"\"\n",
    "    Throws a ValueError if value.shape != expected_shape.\n",
    "    Args:\n",
    "        value: Matrix to shape check.\n",
    "        expected_shape: A tuple or list of integers.\n",
    "        name: An optional name to add to the exception message.\n",
    "    \"\"\"\n",
    "    if value.shape != tuple(expected_shape):\n",
    "        raise ValueError('Shape mismatch %s: Expected %s, got %s' % (name, str(expected_shape), str(value.shape)))\n",
    "    \n",
    "    # TODO: Don't know how to use this function. Write explanation. \n",
    "    def extract_condition(self, hyperparams, m):\n",
    "    \"\"\"\n",
    "    Pull the relevant hyperparameters corresponding to the specified\n",
    "    condition, and return a new hyperparameter dictionary.\n",
    "    \"\"\"\n",
    "    return {var: val[m] if isinstance(val, list) else val for var, val in hyperparams.items()}\n",
    "\n",
    "    def approx_equal(self, a, b, threshold=1e-5):\n",
    "    \"\"\"\n",
    "    Return whether two numbers are equal within an absolute threshold.\n",
    "    Returns:\n",
    "        True if a and b are equal within threshold.\n",
    "    \"\"\"\n",
    "    return np.all(np.abs(a - b) < threshold)\n",
    "\n",
    "    def finite_differences(self, func, inputs, func_output_shape=(), epsilon=1e-5):\n",
    "    \"\"\"\n",
    "    Computes gradients via finite differences.\n",
    "    derivative = (func(x+epsilon) - func(x-epsilon)) / (2*epsilon)\n",
    "    Args:\n",
    "        func: Function to compute gradient of. Inputs and outputs can be\n",
    "            arbitrary dimension.\n",
    "        inputs: Vector value to compute gradient at.\n",
    "        func_output_shape: Shape of the output of func. Default is\n",
    "            empty-tuple, which works for scalar-valued functions.\n",
    "        epsilon: Difference to use for computing gradient.\n",
    "    Returns:\n",
    "        Gradient vector of each dimension of func with respect to each\n",
    "        dimension of input.\n",
    "    \"\"\"\n",
    "    gradient = np.zeros(inputs.shape+func_output_shape)\n",
    "    for idx, _ in np.ndenumerate(inputs):\n",
    "        test_input = np.copy(inputs)\n",
    "        test_input[idx] += epsilon\n",
    "        obj_d1 = func(test_input)\n",
    "        assert obj_d1.shape == func_output_shape\n",
    "        test_input = np.copy(inputs)\n",
    "        test_input[idx] -= epsilon\n",
    "        obj_d2 = func(test_input)\n",
    "        assert obj_d2.shape == func_output_shape\n",
    "        diff = (obj_d1 - obj_d2) / (2 * epsilon)\n",
    "        gradient[idx] += diff\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Linear Gaussian Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearGaussianPolicy(object):\n",
    "    \"\"\"\n",
    "    Time-varying linear Gaussian policy.\n",
    "    U = K*x + k + noise, where noise ~ N(0, chol_pol_covar)\n",
    "    \"\"\"\n",
    "    # TODO: Add additional noise patterns\n",
    "    def __init__(self, K, k, pol_covar, chol_pol_covar, inv_pol_covar, check_shape, verbose=True):\n",
    "        self.verbose = verbose\n",
    "        if self.verbose: \n",
    "            print('-'*25)\n",
    "            print('Call to the class LinearGaussianPolicy has started')\n",
    "            print('-'*25)\n",
    "        \n",
    "        # Assume K has the correct shape, and make sure others match.\n",
    "        self.T = K.shape[0]\n",
    "        self.dU = K.shape[1]\n",
    "        self.dX = K.shape[2]\n",
    "\n",
    "        check_shape(k, (self.T, self.dU))\n",
    "        check_shape(pol_covar, (self.T, self.dU, self.dU))\n",
    "        check_shape(chol_pol_covar, (self.T, self.dU, self.dU))\n",
    "        check_shape(inv_pol_covar, (self.T, self.dU, self.dU))\n",
    "\n",
    "        self.K = K\n",
    "        self.k = k\n",
    "        self.pol_covar = pol_covar\n",
    "        self.chol_pol_covar = chol_pol_covar\n",
    "        self.inv_pol_covar = inv_pol_covar\n",
    "\n",
    "    def act(self, x, obs, t, noise=None):\n",
    "        \"\"\"\n",
    "        Return an action for a state.\n",
    "        Args:\n",
    "            x: State vector.\n",
    "            obs: Observation vector.\n",
    "            t: Time step.\n",
    "            noise: Action noise. This will be scaled by the variance.\n",
    "        \"\"\"\n",
    "        u = self.K[t].dot(x) + self.k[t]\n",
    "        u += self.chol_pol_covar[t].T.dot(noise)\n",
    "        return u\n",
    "\n",
    "    def fold_k(self, noise):\n",
    "        \"\"\"\n",
    "        Fold noise into k.\n",
    "        Args:\n",
    "            noise: A T x dU noise vector with mean 0 and variance 1.\n",
    "        Returns:\n",
    "            k: A T x dU bias vector.\n",
    "        \"\"\"\n",
    "        k = np.zeros_like(self.k)\n",
    "        for i in range(self.T):\n",
    "            scaled_noise = self.chol_pol_covar[i].T.dot(noise[i])\n",
    "            k[i] = scaled_noise + self.k[i]\n",
    "        return k\n",
    "\n",
    "    def nans_like(self):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            A new linear Gaussian policy object with the same dimensions\n",
    "            but all values filled with NaNs.\n",
    "        \"\"\"\n",
    "        policy = LinearGaussianPolicy(\n",
    "            np.zeros_like(self.K), np.zeros_like(self.k),\n",
    "            np.zeros_like(self.pol_covar), np.zeros_like(self.chol_pol_covar),\n",
    "            np.zeros_like(self.inv_pol_covar)\n",
    "        )\n",
    "        policy.K.fill(np.nan)\n",
    "        policy.k.fill(np.nan)\n",
    "        policy.pol_covar.fill(np.nan)\n",
    "        policy.chol_pol_covar.fill(np.nan)\n",
    "        policy.inv_pol_covar.fill(np.nan)\n",
    "        return policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Trajectory Optimization Utilities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class traj_opt_utils(object):\n",
    "    '''\n",
    "    init: defines some important parameters used by this function\n",
    "    '''\n",
    "    def __init__(self, DGD_MAX_ITER=50, DGD_MAX_LS_ITER=20, DGD_MAX_GD_ITER=200, \n",
    "                 ALPHA=0.005, BETA1=0.9, BETA2=0.999, EPS=1e-8, verbose=True):\n",
    "        self.verbose = verbose\n",
    "        if self.verbose:\n",
    "            print('-'*25)\n",
    "            print('Call to the class traj_opt_utils has started')\n",
    "            print('-'*25)\n",
    "        # TODO: Maybe add this parameter to TrajOptLQR\n",
    "        # Constants used in TrajOptLQR.\n",
    "        self.DGD_MAX_ITER = 50\n",
    "        self.DGD_MAX_LS_ITER = 20\n",
    "        self.DGD_MAX_GD_ITER = 200\n",
    "        # Adam parameters\n",
    "        self.ALPHA, self.BETA1, self.BETA2, self.EPS = 0.005, 0.9, 0.999, 1e-8  \n",
    "        \n",
    "    def traj_distr_kl(self, new_mu, new_sigma, new_traj_distr, prev_traj_distr, tot=True):\n",
    "    \"\"\"\n",
    "    Compute KL divergence between new and previous trajectory\n",
    "    distributions.\n",
    "    Args:\n",
    "        new_mu: T x dX, mean of new trajectory distribution.\n",
    "        new_sigma: T x dX x dX, variance of new trajectory distribution.\n",
    "        new_traj_distr: A linear Gaussian policy object, new\n",
    "            distribution.\n",
    "        prev_traj_distr: A linear Gaussian policy object, previous\n",
    "            distribution.\n",
    "        tot: Whether or not to sum KL across all time steps.\n",
    "    Returns:\n",
    "        kl_div: The KL divergence between the new and previous\n",
    "            trajectories.\n",
    "    \"\"\"\n",
    "    # Constants.\n",
    "    T = new_mu.shape[0]\n",
    "    dU = new_traj_distr.dU\n",
    "\n",
    "    # Initialize vector of divergences for each time step.\n",
    "    kl_div = np.zeros(T)\n",
    "\n",
    "    # Step through trajectory.\n",
    "    for t in range(T):\n",
    "        # Fetch matrices and vectors from trajectory distributions.\n",
    "        mu_t = new_mu[t, :]\n",
    "        sigma_t = new_sigma[t, :, :]\n",
    "        K_prev = prev_traj_distr.K[t, :, :]\n",
    "        K_new = new_traj_distr.K[t, :, :]\n",
    "        k_prev = prev_traj_distr.k[t, :]\n",
    "        k_new = new_traj_distr.k[t, :]\n",
    "        chol_prev = prev_traj_distr.chol_pol_covar[t, :, :]\n",
    "        chol_new = new_traj_distr.chol_pol_covar[t, :, :]\n",
    "\n",
    "        # Compute log determinants and precision matrices.\n",
    "        logdet_prev = 2 * sum(np.log(np.diag(chol_prev)))\n",
    "        logdet_new = 2 * sum(np.log(np.diag(chol_new)))\n",
    "        prc_prev = sp.linalg.solve_triangular(\n",
    "            chol_prev, sp.linalg.solve_triangular(chol_prev.T, np.eye(dU),\n",
    "                                                  lower=True)\n",
    "        )\n",
    "        prc_new = sp.linalg.solve_triangular(\n",
    "            chol_new, sp.linalg.solve_triangular(chol_new.T, np.eye(dU),\n",
    "                                                 lower=True)\n",
    "        )\n",
    "\n",
    "        # Construct matrix, vector, and constants.\n",
    "        M_prev = np.r_[\n",
    "            np.c_[K_prev.T.dot(prc_prev).dot(K_prev), -K_prev.T.dot(prc_prev)],\n",
    "            np.c_[-prc_prev.dot(K_prev), prc_prev]\n",
    "        ]\n",
    "        M_new = np.r_[\n",
    "            np.c_[K_new.T.dot(prc_new).dot(K_new), -K_new.T.dot(prc_new)],\n",
    "            np.c_[-prc_new.dot(K_new), prc_new]\n",
    "        ]\n",
    "        v_prev = np.r_[K_prev.T.dot(prc_prev).dot(k_prev),\n",
    "                       -prc_prev.dot(k_prev)]\n",
    "        v_new = np.r_[K_new.T.dot(prc_new).dot(k_new), -prc_new.dot(k_new)]\n",
    "        c_prev = 0.5 * k_prev.T.dot(prc_prev).dot(k_prev)\n",
    "        c_new = 0.5 * k_new.T.dot(prc_new).dot(k_new)\n",
    "\n",
    "        # Compute KL divergence at timestep t.\n",
    "        kl_div[t] = max(\n",
    "            0,\n",
    "            -0.5 * mu_t.T.dot(M_new - M_prev).dot(mu_t) -\n",
    "            mu_t.T.dot(v_new - v_prev) - c_new + c_prev -\n",
    "            0.5 * np.sum(sigma_t * (M_new-M_prev)) - 0.5 * logdet_new +\n",
    "            0.5 * logdet_prev\n",
    "        )\n",
    "\n",
    "    # Add up divergences across time to get total divergence.\n",
    "    return np.sum(kl_div) if tot else kl_div\n",
    "\n",
    "\n",
    "    def traj_distr_kl_alt(self, new_mu, new_sigma, new_traj_distr, prev_traj_distr, tot=True):\n",
    "    \"\"\"\n",
    "    This function computes the same quantity as the function above.\n",
    "    However, it is easier to modify and understand this function, i.e.,\n",
    "    passing in a different mu and sigma to this function will behave properly.\n",
    "    \"\"\"\n",
    "    T, dX, dU = new_mu.shape[0], new_traj_distr.dX, new_traj_distr.dU\n",
    "    kl_div = np.zeros(T)\n",
    "\n",
    "    for t in range(T):\n",
    "        K_prev = prev_traj_distr.K[t, :, :]\n",
    "        K_new = new_traj_distr.K[t, :, :]\n",
    "\n",
    "        k_prev = prev_traj_distr.k[t, :]\n",
    "        k_new = new_traj_distr.k[t, :]\n",
    "\n",
    "        sig_prev = prev_traj_distr.pol_covar[t, :, :]\n",
    "        sig_new = new_traj_distr.pol_covar[t, :, :]\n",
    "\n",
    "        chol_prev = prev_traj_distr.chol_pol_covar[t, :, :]\n",
    "        chol_new = new_traj_distr.chol_pol_covar[t, :, :]\n",
    "\n",
    "        inv_prev = prev_traj_distr.inv_pol_covar[t, :, :]\n",
    "        inv_new = new_traj_distr.inv_pol_covar[t, :, :]\n",
    "\n",
    "        logdet_prev = 2 * sum(np.log(np.diag(chol_prev)))\n",
    "        logdet_new = 2 * sum(np.log(np.diag(chol_new)))\n",
    "\n",
    "        K_diff, k_diff = K_prev - K_new, k_prev - k_new\n",
    "        mu, sigma = new_mu[t, :dX], new_sigma[t, :dX, :dX]\n",
    "\n",
    "        kl_div[t] = max(\n",
    "                0,\n",
    "                0.5 * (logdet_prev - logdet_new - new_traj_distr.dU +\n",
    "                       np.sum(np.diag(inv_prev.dot(sig_new))) +\n",
    "                       k_diff.T.dot(inv_prev).dot(k_diff) +\n",
    "                       mu.T.dot(K_diff.T).dot(inv_prev).dot(K_diff).dot(mu) +\n",
    "                       np.sum(np.diag(K_diff.T.dot(inv_prev).dot(K_diff).dot(sigma))) +\n",
    "                       2 * k_diff.T.dot(inv_prev).dot(K_diff).dot(mu))\n",
    "        )\n",
    "\n",
    "    return np.sum(kl_div) if tot else kl_div\n",
    "\n",
    "\n",
    "    def approximated_cost(self, sample_list, traj_distr, traj_info):\n",
    "    \"\"\"\n",
    "    This function gives the LQR estimate of the cost function given the noise\n",
    "    experienced along each sample in sample_list.\n",
    "    Args:\n",
    "        sample_list: List of samples to extract noise from.\n",
    "        traj_distr: LQR controller to roll forward.\n",
    "        traj_info: Used to obtain dynamics estimate to simulate trajectories.\n",
    "    Returns:\n",
    "        mu_all: Trajectory means corresponding to each sample in sample_list.\n",
    "        predicted_cost: LQR estimates of cost of each sample in sample_list.\n",
    "    \"\"\"\n",
    "    T = traj_distr.T\n",
    "    N = len(sample_list)\n",
    "    dU = traj_distr.dU\n",
    "    dX = traj_distr.dX\n",
    "    noise = sample_list.get_noise()\n",
    "\n",
    "    # Constants.\n",
    "    idx_x = slice(dX)\n",
    "    mu_all = np.zeros((N, T, dX+dU))\n",
    "\n",
    "    # Pull out dynamics.\n",
    "    Fm = traj_info.dynamics.Fm\n",
    "    fv = traj_info.dynamics.fv\n",
    "    dyn_covar = traj_info.dynamics.dyn_covar\n",
    "\n",
    "    for i in range(N):\n",
    "        mu = np.zeros((T, dX+dU))\n",
    "        mu[0, idx_x] = traj_info.x0mu\n",
    "        for t in range(T):\n",
    "            mu[t, :] = np.hstack([\n",
    "                mu[t, idx_x],\n",
    "                (traj_distr.K[t, :, :].dot(mu[t, idx_x]) + traj_distr.k[t, :]\n",
    "                 + traj_distr.chol_pol_covar[t].T.dot(noise[i, t]))\n",
    "            ])\n",
    "            if t < T - 1:\n",
    "                mu[t+1, idx_x] = Fm[t, :, :].dot(mu[t, :]) + fv[t, :]\n",
    "        mu_all[i, :, :] = mu\n",
    "\n",
    "    # Compute cost.\n",
    "    predicted_cost = np.zeros((N, T))\n",
    "\n",
    "    for i in range(N):\n",
    "        for t in range(T):\n",
    "            predicted_cost[i, t] = traj_info.cc[t] + \\\n",
    "                    0.5 * mu_all[i,t,:].T.dot(traj_info.Cm[t, :, :]).dot(mu_all[i,t,:]) + \\\n",
    "                    mu_all[i,t,:].T.dot(traj_info.cv[t, :])\n",
    "\n",
    "    return mu_all, predicted_cost\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrap code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside test function, arg pass func test success\n"
     ]
    }
   ],
   "source": [
    "# algorithm = {\n",
    "#     'type': 'init_lqr',\n",
    "#     'init_gains': np.zeros(6),\n",
    "#     'init_acc': np.zeros(6),\n",
    "#     'init_var': 0.1,\n",
    "#     'stiffness': 0.01,\n",
    "#     'dt': 1,\n",
    "#     'T': 2,\n",
    "# }\n",
    "# INIT_LG_LQR = {\n",
    "#     'wow': algorithm,\n",
    "#     'init_var': 1,\n",
    "#     'stiffness': 2,\n",
    "#     'stiffness_vel': 3,\n",
    "#     'final_weight': 4,\n",
    "#     # Parameters for guessing dynamics\n",
    "#     # dU vector of accelerations, default zeros.\n",
    "#     'init_acc': [],  \n",
    "#     # dU vector of gains, default ones.\n",
    "#     'init_gains': [],  \n",
    "# }\n",
    "\n",
    "# check_shape(np.full((10), (10)), (10,), 'Sam')\n",
    "\n",
    "# temp = range(10)\n",
    "# b = extract_condition(algorithm, temp)\n",
    "# b = extract_condition(INIT_LG_LQR, temp[0])\n",
    "# print(b)\n",
    "# for var, val in INIT_LG_LQR.items():\n",
    "#     if isinstance(val, list):\n",
    "#         print('in if')\n",
    "#         a = {var: val[1]}\n",
    "#         print(a)\n",
    "#     else:\n",
    "#         print('in else')\n",
    "#         print(val)\n",
    "\n",
    "# def test():\n",
    "#     print('inside test function, arg pass func test success')\n",
    "    \n",
    "# class a(object):\n",
    "#     def try_new(self, new_func):\n",
    "#         new_func()\n",
    "        \n",
    "# wow = a()\n",
    "# wow.try_new(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gen_param_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-0784ea712566>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_param_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_param_ALG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gen_param_dict' is not defined"
     ]
    }
   ],
   "source": [
    "param = gen_param_dict()\n",
    "a = param.gen_param_ALG()\n",
    "print(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
