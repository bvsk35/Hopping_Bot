{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ef2574594168>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-ef2574594168>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-ef2574594168>\u001b[0m in \u001b[0;36mtest_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'In test function'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "class a(object):\n",
    "    def __init__(self, test='A'):\n",
    "        print(test)\n",
    "        \n",
    "    def test_fun(self):\n",
    "        print('In test function', test)\n",
    "        \n",
    "class b(object):\n",
    "    def __init__(self):\n",
    "        X = a()\n",
    "        X.test_fun()\n",
    "        \n",
    "y = b()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GMM Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gaussian_Mixture_Model(object):\n",
    "    \"\"\"Init Function\"\"\"\n",
    "    def __init__(self, init_sequential=False, eigreg=False, warmstart=True):\n",
    "        \"\"\" Gaussian Mixture Model:\n",
    "            init_sequential: Cluster indices\n",
    "        \"\"\"\n",
    "        # Parameters (need more explanation??)\n",
    "        self.init_sequential = init_sequential \n",
    "        self.eigreg = eigreg\n",
    "        self.warmstart = warmstart\n",
    "        self.sigma = None\n",
    "        \n",
    "    # Need information regarding the function\n",
    "    def logsum(self, vec, axis=0, keepdims=True):\n",
    "        maxv = np.max(vec, axis=axis, keepdims=keepdims)\n",
    "        maxv[maxv == -float('inf')] = 0\n",
    "        return np.log(np.sum(np.exp(vec-maxv), axis=axis, keepdims=keepdims)) + maxv\n",
    "    \n",
    "    # Need information regarding the function\n",
    "    def inference(self, pts):\n",
    "        \"\"\"\n",
    "        Evaluate dynamics prior.\n",
    "        Args:\n",
    "            Pts: Matrix of points and of size (N x D).\n",
    "        \"\"\"\n",
    "        # Compute posterior cluster weights.\n",
    "        logwts = self.clusterwts(pts)\n",
    "\n",
    "        # Compute posterior mean and covariance.\n",
    "        mu0, Phi = self.moments(logwts)\n",
    "\n",
    "        # Set hyperparameters.\n",
    "        m = self.N\n",
    "        n0 = m - 2 - mu0.shape[0]\n",
    "\n",
    "        # Normalize.\n",
    "        m = float(m) / self.N\n",
    "        n0 = float(n0) / self.N\n",
    "        return mu0, Phi, m, n0\n",
    "    \n",
    "    # Need information regarding the function\n",
    "    def estep(self, data):\n",
    "        \"\"\"\n",
    "        Compute Log observation probabilities under GMM.\n",
    "        Args:\n",
    "            data: Matrix of points of size (N x D).\n",
    "        Returns:\n",
    "            logobs: Matrix of log probabilities (for each point on each cluster) and of size (N x K).\n",
    "        Note: \n",
    "            solve_triangular: Solve the equation a x = b for x, assuming a is a triangular matrix.\n",
    "        \"\"\"\n",
    "        # Constants.\n",
    "        N, D = data.shape\n",
    "        K = self.sigma.shape[0]\n",
    "\n",
    "        logobs = -0.5 * np.ones((N, K)) * D * np.log(2*np.pi)\n",
    "        for i in range(K):\n",
    "            mu, sigma = self.mu[i], self.sigma[i]\n",
    "            L = linalg.cholesky(sigma, lower=True)\n",
    "            logobs[:, i] -= np.sum(np.log(np.diag(L)))\n",
    "\n",
    "            diff = (data - mu).T\n",
    "            soln = linalg.solve_triangular(L, diff, lower=True)\n",
    "            logobs[:, i] -= 0.5 * np.sum(soln**2, axis=0)\n",
    "\n",
    "        logobs += self.logmass.T\n",
    "        return logobs\n",
    "    \n",
    "    # Need information regarding the function\n",
    "    def moments(self, logwts):\n",
    "        \"\"\"\n",
    "        Compute the moments of the cluster mixture with logwts.\n",
    "        Args:\n",
    "            logwts: Matrix of log cluster probabilities and of size (K x 1).\n",
    "        Returns:\n",
    "            mu: Mean vector of size (D,).\n",
    "            sigma: Covariance matrix of size (D x D).\n",
    "        \"\"\"\n",
    "        # Exponentiate.\n",
    "        wts = np.exp(logwts)\n",
    "\n",
    "        # Compute overall mean.\n",
    "        mu = np.sum(self.mu * wts, axis=0)\n",
    "\n",
    "        # Compute overall covariance.\n",
    "        diff = self.mu - np.expand_dims(mu, axis=0)\n",
    "        diff_expand = np.expand_dims(self.mu, axis=1) * np.expand_dims(diff, axis=2)\n",
    "        wts_expand = np.expand_dims(wts, axis=2)\n",
    "        sigma = np.sum((self.sigma + diff_expand) * wts_expand, axis=0)\n",
    "        return mu, sigma\n",
    "    \n",
    "    # Need information regarding the function\n",
    "    def clusterwts(self, data):\n",
    "        \"\"\"\n",
    "        Compute cluster weights for specified points under GMM.\n",
    "        Args:\n",
    "            data: Matrix of points and of size (N x D).\n",
    "        Returns:\n",
    "            Column vector of average cluster log probabilities and of size (K x 1).\n",
    "        \"\"\"\n",
    "        # Compute probability of each point under each cluster.\n",
    "        logobs = self.estep(data)\n",
    "\n",
    "        # Renormalize to get cluster weights.\n",
    "        logwts = logobs - self.logsum(logobs, axis=1)\n",
    "\n",
    "        # Average the cluster probabilities.\n",
    "        logwts = self.logsum(logwts, axis=0) - np.log(data.shape[0])\n",
    "        return logwts.T\n",
    "    \n",
    "    # Need information regarding the function\n",
    "    def update(self, data, K, max_iterations=100):\n",
    "        \"\"\"\n",
    "        Run EM to update clusters.\n",
    "        Args:\n",
    "            data: An N x D data matrix, where N = number of data points.\n",
    "            K: Number of clusters to use.\n",
    "        \"\"\"\n",
    "        # Constants.\n",
    "        N = data.shape[0]\n",
    "        Do = data.shape[1]\n",
    "\n",
    "        if (not self.warmstart or self.sigma is None or K != self.sigma.shape[0]):\n",
    "            # Initialization.\n",
    "            self.sigma = np.zeros((K, Do, Do))\n",
    "            self.mu = np.zeros((K, Do))\n",
    "            self.logmass = np.log(1.0 / K) * np.ones((K, 1))\n",
    "            self.mass = (1.0 / K) * np.ones((K, 1))\n",
    "            self.N = data.shape[0]\n",
    "            N = self.N\n",
    "\n",
    "            # Set initial cluster indices.\n",
    "            if not self.init_sequential:\n",
    "                cidx = np.random.randint(0, K, size=(1, N))\n",
    "            else:\n",
    "                raise NotImplementedError()\n",
    "\n",
    "            # Initialize.\n",
    "            for i in range(K):\n",
    "                cluster_idx = (cidx == i)[0]\n",
    "                mu = np.mean(data[cluster_idx, :], axis=0)\n",
    "                diff = (data[cluster_idx, :] - mu).T\n",
    "                sigma = (1.0 / K) * (diff.dot(diff.T))\n",
    "                self.mu[i, :] = mu\n",
    "                self.sigma[i, :, :] = sigma + np.eye(Do) * 2e-6\n",
    "\n",
    "        prevll = -float('inf')\n",
    "        for itr in range(max_iterations):\n",
    "            # E-step: compute cluster probabilities.\n",
    "            logobs = self.estep(data)\n",
    "\n",
    "            # Compute log-likelihood.\n",
    "            ll = np.sum(self.logsum(logobs, axis=1))\n",
    "            if ll < prevll:\n",
    "                # TODO: Why does log-likelihood decrease sometimes?\n",
    "                break\n",
    "            if np.abs(ll-prevll) < 1e-5*prevll:\n",
    "                break\n",
    "            prevll = ll\n",
    "\n",
    "            # Renormalize to get cluster weights.\n",
    "            logw = logobs - self.logsum(logobs, axis=1)\n",
    "            assert logw.shape == (N, K)\n",
    "\n",
    "            # Renormalize again to get weights for refitting clusters.\n",
    "            logwn = logw - self.logsum(logw, axis=0)\n",
    "            assert logwn.shape == (N, K)\n",
    "            w = np.exp(logwn)\n",
    "\n",
    "            # M-step: update clusters.\n",
    "            # Fit cluster mass.\n",
    "            self.logmass = self.logsum(logw, axis=0).T\n",
    "            self.logmass = self.logmass - self.logsum(self.logmass, axis=0)\n",
    "            assert self.logmass.shape == (K, 1)\n",
    "            self.mass = np.exp(self.logmass)\n",
    "            # Reboot small clusters.\n",
    "            w[:, (self.mass < (1.0 / K) * 1e-4)[:, 0]] = 1.0 / N\n",
    "            # Fit cluster means.\n",
    "            w_expand = np.expand_dims(w, axis=2)\n",
    "            data_expand = np.expand_dims(data, axis=1)\n",
    "            self.mu = np.sum(w_expand * data_expand, axis=0)\n",
    "            # Fit covariances.\n",
    "            wdata = data_expand * np.sqrt(w_expand)\n",
    "            assert wdata.shape == (N, K, Do)\n",
    "            for i in range(K):\n",
    "                # Compute weighted outer product.\n",
    "                XX = wdata[:, i, :].T.dot(wdata[:, i, :])\n",
    "                mu = self.mu[i, :]\n",
    "                self.sigma[i, :, :] = XX - np.outer(mu, mu)\n",
    "\n",
    "                if self.eigreg:  # Use eigenvalue regularization.\n",
    "                    raise NotImplementedError()\n",
    "                else:  # Use quick and dirty regularization.\n",
    "                    sigma = self.sigma[i, :, :]\n",
    "                    self.sigma[i, :, :] = 0.5 * (sigma + sigma.T) + 1e-6 * np.eye(Do)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prior_Dynamics_GMM(object):\n",
    "    \"\"\"\n",
    "    A dynamics prior encoded as a GMM over [x_t, u_t, x_t+1] points.\n",
    "    See:\n",
    "        S. Levine*, C. Finn*, T. Darrell, P. Abbeel, \"End-to-end\n",
    "        training of Deep Visuomotor Policies\", arXiv:1504.00702,\n",
    "        Appendix A.3.\n",
    "    \"\"\"\n",
    "    def __init__(self, GMM):\n",
    "        \"\"\"\n",
    "        Hyperparameters:\n",
    "            min_samples_per_cluster: Minimum samples per cluster.\n",
    "            max_clusters: Maximum number of clusters to fit.\n",
    "            max_samples: Maximum number of trajectories to use for fitting the GMM at any given time.\n",
    "            strength: Adjusts the strength of the prior.\n",
    "        \"\"\"\n",
    "        self._min_samples_per_cluster = 20\n",
    "        self._max_clusters = 50\n",
    "        self._max_samples = 20\n",
    "        self._strength = 1.0\n",
    "        self.X = None\n",
    "        self.U = None\n",
    "        self.gmm = GMM\n",
    "\n",
    "    def initial_state(self):\n",
    "        \"\"\" Return dynamics prior for initial time step. \"\"\"\n",
    "        # Compute mean and covariance.\n",
    "        mu0 = np.mean(self.X[:, 0, :], axis=0)\n",
    "        Phi = np.diag(np.var(self.X[:, 0, :], axis=0))\n",
    "\n",
    "        # Factor in multiplier.\n",
    "        n0 = self.X.shape[2] * self._strength\n",
    "        m = self.X.shape[2] * self._strength\n",
    "\n",
    "        # Multiply Phi by m (since it was normalized before).\n",
    "        Phi = Phi * m\n",
    "        return mu0, Phi, m, n0\n",
    "\n",
    "    def update(self, X, U):\n",
    "        \"\"\"\n",
    "        Update prior with additional data.\n",
    "        Args:\n",
    "            X: (N x T x dX) matrix of sequential state data.\n",
    "            U: (N x T x dU) matrix of sequential control data.\n",
    "        \"\"\"\n",
    "        # Constants.\n",
    "        T = X.shape[1] - 1\n",
    "\n",
    "        # Append data to dataset.\n",
    "        if self.X is None:\n",
    "            self.X = X\n",
    "        else:\n",
    "            self.X = np.concatenate([self.X, X], axis=0)\n",
    "\n",
    "        if self.U is None:\n",
    "            self.U = U\n",
    "        else:\n",
    "            self.U = np.concatenate([self.U, U], axis=0)\n",
    "\n",
    "        # Remove excess samples from dataset.\n",
    "        start = max(0, self.X.shape[0] - self._max_samples + 1)\n",
    "        self.X = self.X[start:, :]\n",
    "        self.U = self.U[start:, :]\n",
    "\n",
    "        # Compute cluster dimensionality.\n",
    "        Do = X.shape[2] + U.shape[2] + X.shape[2]  #TODO: Use Xtgt.\n",
    "\n",
    "        # Create dataset.\n",
    "        N = self.X.shape[0]\n",
    "        xux = np.reshape(\n",
    "            np.c_[self.X[:, :T, :], self.U[:, :T, :], self.X[:, 1:(T+1), :]],\n",
    "            [T * N, Do]\n",
    "        )\n",
    "\n",
    "        # Choose number of clusters.\n",
    "        K = int(max(2, min(self._max_clusters,\n",
    "                           np.floor(float(N * T) / self._min_samp))))\n",
    "\n",
    "        # Update GMM.\n",
    "        self.gmm.update(xux, K)\n",
    "\n",
    "    def eval(self, Dx, Du, pts):\n",
    "        \"\"\"\n",
    "        Evaluate prior.\n",
    "        Args:\n",
    "            pts: A N x Dx+Du+Dx matrix.\n",
    "        \"\"\"\n",
    "        # Construct query data point by rearranging entries and adding\n",
    "        # in reference.\n",
    "        assert pts.shape[1] == Dx + Du + Dx\n",
    "\n",
    "        # Perform query and fix mean.\n",
    "        mu0, Phi, m, n0 = self.gmm.inference(pts)\n",
    "\n",
    "        # Factor in multiplier.\n",
    "        n0 = n0 * self._strength\n",
    "        m = m * self._strength\n",
    "\n",
    "        # Multiply Phi by m (since it was normalized before).\n",
    "        Phi *= m\n",
    "        return mu0, Phi, m, n0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Estimated_Dynamics_Prior(object):\n",
    "    \"\"\" Dynamics with linear regression, with arbitrary prior. \"\"\"\n",
    "    def __init__(self, Prior_Dynamics):\n",
    "        self.Fm = None\n",
    "        self.fv = None\n",
    "        self.dyn_covar = None\n",
    "        self.prior = Prior_Dynamics\n",
    "\n",
    "    def update_prior(self, X, U):\n",
    "        \"\"\" Update dynamics prior. \"\"\"\n",
    "        self.prior.update(X, U)\n",
    "    \n",
    "    def gauss_fit_joint_prior(self, pts, mu0, Phi, m, n0, dwts, dX, dU, sig_reg):\n",
    "        \"\"\" Perform Gaussian fit to data with a prior. \"\"\"\n",
    "        # Build weights matrix.\n",
    "        D = np.diag(dwts)\n",
    "        # Compute empirical mean and covariance.\n",
    "        mun = np.sum((pts.T * dwts).T, axis=0)\n",
    "        diff = pts - mun\n",
    "        empsig = diff.T.dot(D).dot(diff)\n",
    "        empsig = 0.5 * (empsig + empsig.T)\n",
    "        # MAP estimate of joint distribution.\n",
    "        N = dwts.shape[0]\n",
    "        mu = mun\n",
    "        sigma = (N * empsig + Phi + (N * m) / (N + m) *\n",
    "                 np.outer(mun - mu0, mun - mu0)) / (N + n0)\n",
    "        sigma = 0.5 * (sigma + sigma.T)\n",
    "        # Add sigma regularization.\n",
    "        sigma += sig_reg\n",
    "        # Conditioning to get dynamics.\n",
    "        fd = np.linalg.solve(sigma[:dX, :dX], sigma[:dX, dX:dX+dU]).T\n",
    "        fc = mu[dX:dX+dU] - fd.dot(mu[:dX])\n",
    "        dynsig = sigma[dX:dX+dU, dX:dX+dU] - fd.dot(sigma[:dX, :dX]).dot(fd.T)\n",
    "        dynsig = 0.5 * (dynsig + dynsig.T)\n",
    "        return fd, fc, dynsig\n",
    "\n",
    "    def fit(self, X, U):\n",
    "        \"\"\" Fit dynamics. \"\"\"\n",
    "        N, T, dX = X.shape\n",
    "        dU = U.shape[2]\n",
    "\n",
    "        if N == 1:\n",
    "            raise ValueError(\"Cannot fit dynamics on 1 sample\")\n",
    "\n",
    "        self.Fm = np.zeros([T, dX, dX+dU])\n",
    "        self.fv = np.zeros([T, dX])\n",
    "        self.dyn_covar = np.zeros([T, dX, dX])\n",
    "\n",
    "        it = slice(dX+dU)\n",
    "        ip = slice(dX+dU, dX+dU+dX)\n",
    "        # Fit dynamics with least squares regression.\n",
    "        dwts = (1.0 / N) * np.ones(N)\n",
    "        for t in range(T - 1):\n",
    "            Ys = np.c_[X[:, t, :], U[:, t, :], X[:, t+1, :]]\n",
    "            # Obtain Normal-inverse-Wishart prior.\n",
    "            mu0, Phi, mm, n0 = self.prior.eval(dX, dU, Ys)\n",
    "            sig_reg = np.zeros((dX+dU+dX, dX+dU+dX))\n",
    "            sig_reg[it, it] = 1e-6\n",
    "            Fm, fv, dyn_covar = self.gauss_fit_joint_prior(Ys, mu0, Phi, mm, n0, dwts, dX+dU, dX, sig_reg)\n",
    "            self.Fm[t, :, :] = Fm\n",
    "            self.fv[t, :] = fv\n",
    "            self.dyn_covar[t, :, :] = dyn_covar\n",
    "        return self.Fm, self.fv, self.dyn_covar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
